{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import misc\n",
    "import pprint as pp\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/albert/github/DenseNet/')\n",
    "import densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mine Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CAFFE_ROOT = '/home/albert/caffe/'\n",
    "img_dir = os.listdir(CAFFE_ROOT + 'data/market-1501/bounding_box_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_files = {}\n",
    "train_arr = []\n",
    "labels = []\n",
    "\n",
    "for f in img_dir:\n",
    "    if f[-4:] == '.jpg':\n",
    "        idt = int(f[0:f.index('_')])\n",
    "        if not any(idt == l for l in labels):\n",
    "            labels.append(idt)\n",
    "            train_files[idt] = []\n",
    "        path = CAFFE_ROOT + 'data/market-1501/bounding_box_train/' + f\n",
    "        train_files[idt].append(path)\n",
    "        train_arr.append([path, idt])\n",
    "\n",
    "labels.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of identities\n",
    "P_param = 18\n",
    "# Number of images per identity\n",
    "K_param = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "    out = np.copy(img) * 255\n",
    "    out = out[:, :, [2,1,0]] # swap channel from RGB to BGR\n",
    "    out[:,:,0] -= VGG_MEAN[0]\n",
    "    out[:,:,1] -= VGG_MEAN[1]\n",
    "    out[:,:,2] -= VGG_MEAN[2]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.125,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_batch_generator(train_files, labels, P=P_param, K=K_param):\n",
    "    while True:\n",
    "        batch = []\n",
    "        idt_choice = np.random.choice(labels, P, replace=False)\n",
    "        for p in range(len(idt_choice)):\n",
    "            if K > len(train_files[idt_choice[p]]):\n",
    "                k_choice = np.random.choice(range(len(train_files[idt_choice[p]])), K, replace=True)\n",
    "            else:\n",
    "                k_choice = np.random.choice(range(len(train_files[idt_choice[p]])), K, replace=False)\n",
    "            for k in k_choice:\n",
    "                path = train_files[idt_choice[p]][k]\n",
    "                img = misc.imread(path).astype(np.float64)\n",
    "                batch.append(img.tolist())\n",
    "        output = np.array(batch)\n",
    "        yield(output, np.zeros((P*K, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log1p(x):\n",
    "    return Keras.log(1 + Keras.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(x1, x2):\n",
    "    return Keras.sum(Keras.abs(x1 - x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, margin=0.5, P=P_param, K=K_param, output_dim = 128):\n",
    "    embeddings = Keras.reshape(y_pred, (-1, output_dim))\n",
    "\n",
    "    loss = tf.Variable(1, dtype=tf.float32)\n",
    "\n",
    "    for i in range(P):\n",
    "        for a in range(K):\n",
    "            pred_anchor = embeddings[i*K + a]\n",
    "            hard_pos = Keras.max(dist(pred_anchor, embeddings[i*K:(i + 1)*K]))\n",
    "            hard_neg = Keras.min(dist(pred_anchor, Keras.concatenate([embeddings[0:i*K],\n",
    "                                                                      embeddings[(i + 1)*K:]], 0)))\n",
    "            loss += margin + hard_pos - hard_neg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_rank(net, rank, all_embeddings, all_identities, test_iter=1000):\n",
    "    correct = 0\n",
    "    f_choice = np.random.choice(range(len(train_arr)), np.minimum(test_iter, len(train_arr)), replace=False)\n",
    "    for f in f_choice:\n",
    "        query_img = misc.imread(train_arr[f][0])\n",
    "        query_embedding = net.predict(query_img.reshape(1, 128, 64, 3))\n",
    "        distance_vectors = np.squeeze(np.abs(all_embeddings - query_embedding))\n",
    "        distance = np.sum(distance_vectors, axis=1)\n",
    "        top_inds = distance.argsort()[:rank+1]\n",
    "        output_classes = np.array(all_identities)[top_inds].astype(np.uint16)\n",
    "        \n",
    "#         pp.pprint(zip(distance[top_inds], np.array(all_identities)[top_inds].astype(np.uint16)))\n",
    "        \n",
    "        i = 0\n",
    "        for c in output_classes:\n",
    "            if c == int(train_arr[f][1]):\n",
    "                i += 1\n",
    "        if i > 1:\n",
    "            correct += 1\n",
    "#         print(correct)\n",
    "    return float(correct)/test_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the triplet loss paper, use an adaptive learning rate decay that is constant at first, then decays exponentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://medium.com/towards-data-science/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
    "from keras.callbacks import LearningRateScheduler, History\n",
    "\n",
    "# Rank 20: 0.206, 0.193, 0.206\n",
    "def step_decay(epoch):\n",
    "    initial_lr = 0.0003\n",
    "    drop = 0.7\n",
    "    epochs_drop = 5\n",
    "    lrate = initial_lr * np.power(drop,  \n",
    "           np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "# def step_decay(epoch):\n",
    "#     init_lr = 0.0003\n",
    "#     epochs_0 = 15.0\n",
    "#     epochs_1 = 30.0\n",
    "#     if epoch < epochs_0:\n",
    "#         return init_lr\n",
    "#     else:\n",
    "#         return init_lr * np.power(0.001, (epoch - epochs_0)/(epochs_1 - epochs_0))\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f72e0163990>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuU3WV97/H3Z/bcMjOZTG5M7iRIlAa1EcYQKypLxCYc\n6tDTloZDTYrUSIHWetpV4znH9vQsuw61Z7WVJSUHlZJobWTVWmKNRsyRtmoDCUKBgDExXJKQhAmX\n3C9z+Z4/9m9gd0hmX2Ymv9nz+7zW2mvv37Of57efh0s++T3P76KIwMzMrBI1aXfAzMyql0PEzMwq\n5hAxM7OKOUTMzKxiDhEzM6uYQ8TMzCrmEDEzs4o5RMzMrGIOETMzq1ht2h0YaVOmTIm5c+em3Q0z\ns6ryyCOPHIyIqcXqjfkQmTt3Llu3bk27G2ZmVUXSc6XU83SWmZlVzCFiZmYVc4iYmVnFHCJmZlYx\nh4iZmVWspBCRtETSdkk7Ja06w/eSdEfy/eOSLinWVtIkSQ9I2pG8T0zKF0l6LHn9u6RfLmhzqaQn\nkn3dIUlDG76ZmQ1F0RCRlAPuBJYCC4DrJS0YUG0pMD95rQTuKqHtKmBTRMwHNiXbAE8CHRGxEFgC\n/F9J/aci3wV8tOC3lpQ7YDMzGz6lXCeyCNgZEbsAJK0DOoGnCup0Amsj/6zdzZLaJE0H5g7SthO4\nImm/BngQ+GREHC/YbyMQSdvpQGtEbE621wLXAt8ub8ilufeHz/DysdNF6719VhsfWNA+El0wMxv1\nSgmRmcDugu09wGUl1JlZpG17ROxLPu8HXvuTWNJlwD3A+cCHI6JH0syk/cDfeANJK8kfETFnzpwi\nwzuzrz78PDtePDponQg4b3yDQ8TMMmtUXLEeESEpCrYfAi6W9HPAGkllHW1ExN3A3QAdHR1RpPoZ\nffcT7yta50+/9RRf2fx8Jbs3MxsTSllY3wvMLtielZSVUmewtgeSKar+qaoXB/5wRDwNHAXemrSb\nVaQf51RzQy0nunvp7asop8zMql4pIbIFmC9pnqR6YBmwfkCd9cDy5CytxcChZKpqsLbrgRXJ5xXA\n/QBJ3drk8/nARcCzyf4OS1qcnJW1vL9NWloa8gdyR0/1pNkNM7PUFJ3OStYjbgM2AjngnojYJunm\n5PvVwAbgamAncBy4cbC2ya5vB+6TdBPwHHBdUn45sEpSN9AH3BIRB5PvbgHuBcaRX1AfkUX1UvWH\nyLFTPUwYV5dmV8zMUlHSmkhEbCAfFIVlqws+B3BrqW2T8peAK89Q/mXgy2fZ11byU1ujQnNBiJiZ\nZZGvWB8CT2eZWdY5RIag2SFiZhnnEBmCFk9nmVnGOUSG4PXprN6Ue2Jmlg6HyBA0N+QAH4mYWXY5\nRIbAayJmlnUOkSFoqK2hLieHiJlllkNkCCTR3FDr6SwzyyyHyBA119dy9KRDxMyyySEyRC0NtZ7O\nMrPMcogMUUtjLcdOO0TMLJscIkPU3FDr60TMLLMcIkPU0pDj6MnutLthZpYKh8gQNdfXcsxHImaW\nUQ6RIWpp9Cm+ZpZdDpEhammo5ejpHvKPVDEzyxaHyBA1N9QSAcdPe0rLzLLHITJEfrqhmWWZQ2SI\nxvsmjGaWYQ6RIXr9SMTTWWaWPQ6RIep/psiRU75WxMyyxyEyRC0+EjGzDHOIDJGfs25mWeYQGaL+\nEDniEDGzDCopRCQtkbRd0k5Jq87wvSTdkXz/uKRLirWVNEnSA5J2JO8Tk/KrJD0i6Ynk/f0FbR5M\n9vVY8jpvaMMfOp/ia2ZZVjREJOWAO4GlwALgekkLBlRbCsxPXiuBu0pouwrYFBHzgU3JNsBB4Jci\n4m3ACuDLA37rhohYmLxeLGewI6GpPofkEDGzbCrlSGQRsDMidkXEaWAd0DmgTiewNvI2A22Sphdp\n2wmsST6vAa4FiIhHI+KFpHwbME5SQ4XjG3GSaKn3g6nMLJtKCZGZwO6C7T1JWSl1BmvbHhH7ks/7\ngfYz/PavAD+OiFMFZWuSqaxPS9KZOixppaStkrZ2dXUNMrTh0dzgR+SaWTaNioX1yN+98D/cwVDS\nxcCfAR8rKL4hIi4G3pO8PnyW/d0dER0R0TF16tQR6vXrmhtyfrqhmWVSKSGyF5hdsD0rKSulzmBt\nDyRTXiTvr61vSJoFfANYHhE/6y+PiL3J+xHgq+Sny1LX4qcbmllGlRIiW4D5kuZJqgeWAesH1FkP\nLE/O0loMHEqmqgZru578wjnJ+/0AktqAbwGrIuKH/T8gqVbSlORzHXAN8GTZIx4BfqaImWVVbbEK\nEdEj6TZgI5AD7omIbZJuTr5fDWwArgZ2AseBGwdrm+z6duA+STcBzwHXJeW3ARcCfyTpj5KyDwLH\ngI1JgOSA7wFfGMrgh0tzfS0HjxxPuxtmZudc0RABiIgN5IOisGx1wecAbi21bVL+EnDlGco/A3zm\nLF25tJT+nmv56SwfiZhZ9oyKhfVq19xQ64V1M8skh8gw6F8T8SNyzSxrHCLDoKWhlu7e4FRPX9pd\nMTM7pxwiw6C5Pv9MEZ+hZWZZ4xAZBn66oZlllUNkGIxv7L8dvJ9uaGbZ4hAZBj4SMbOscogMAz9T\nxMyyyiEyDPqfbugLDs0saxwiw8AhYmZZ5RAZBp7OMrOscogMg/7rRHwkYmZZ4xAZBrW5Ghrranwk\nYmaZ4xAZJi0NdT4SMbPMcYgMk5aGnJ9uaGaZ4xAZJs0NfrqhmWWPQ2SYNDfUcvSkQ8TMssUhMkzG\n++mGZpZBDpFh4qcbmlkWlfSMdSuuuaGWwye62fni0ZLbNNXnmNE2bgR7ZWY2shwiw2Rycz2vHO/m\nA3/xz2W1++Ztl/O2WRNGqFdmZiPLITJMPvqeC7ho+nj6SnzM+oFDJ/nTDU/z/MvHHSJmVrUcIsNk\nQlMd17x9Rsn1DxzOh8grx0+PYK/MzEaWF9ZT0tZUB8CrDhEzq2IlhYikJZK2S9opadUZvpekO5Lv\nH5d0SbG2kiZJekDSjuR9YlJ+laRHJD2RvL+/oM2lSfnO5Pc0tOGnp6E2R1N9jleO+5G6Zla9ioaI\npBxwJ7AUWABcL2nBgGpLgfnJayVwVwltVwGbImI+sCnZBjgI/FJEvA1YAXy54HfuAj5a8FtLyhns\naDOxqd7TWWZW1Uo5ElkE7IyIXRFxGlgHdA6o0wmsjbzNQJuk6UXadgJrks9rgGsBIuLRiHghKd8G\njJPUkOyvNSI2R0QAa/vbVKu2pjpe9ZGImVWxUkJkJrC7YHtPUlZKncHatkfEvuTzfqD9DL/9K8CP\nI+JU0m5PkX4AIGmlpK2StnZ1dZ1tXKnzkYiZVbtRsbCeHFn8h5NjJV0M/BnwsQr2d3dEdEREx9Sp\nU4epl8PPRyJmVu1KCZG9wOyC7VlJWSl1Bmt7IJmiInl/sb+SpFnAN4DlEfGzgt+YVaQfVcVHImZW\n7UoJkS3AfEnzJNUDy4D1A+qsB5YnZ2ktBg4lU1WDtV1PfuGc5P1+AEltwLeAVRHxw/4fSPZ3WNLi\n5Kys5f1tqtXEpjoOneimt9QrFM3MRpmiIRIRPcBtwEbgaeC+iNgm6WZJNyfVNgC7gJ3AF4BbBmub\ntLkduErSDuADyTZJ/QuBP5L0WPI6L/nuFuCLye/8DPh2xSMfBSY01RMBh094SsvMqlNJV6xHxAby\nQVFYtrrgcwC3lto2KX8JuPIM5Z8BPnOWfW0F3lpKn6vBxOSCw1eOn2Zic33KvTEzK9+oWFjPqolN\n+eDwBYdmVq0cIinyrU/MrNo5RFLUfyTi03zNrFo5RFL0+nSWj0TMrDo5RFI0vrGWGvlIxMyql0Mk\nRTU1os0XHJpZFXOIpMy3PjGzauYQSZlvfWJm1cwhkrKJTXW+TsTMqpZDJGVtTfW+TsTMqpZDJGX5\nIxGHiJlVJ4dIytqa6jnZ3cfJ7t60u2JmVjaHSMp8waGZVTOHSMpeu5PvMS+um1n1cYikrO21+2f5\nSMTMqo9DJGUTm/ufKeIjETOrPg6RlHlNxMyqmUMkZRPG+ZkiZla9HCIpa6zLMa4u5+ksM6tKDpFR\nwBccmlm1coiMAvlbn/hIxMyqj0NkFJjYXOc1ETOrSg6RUcBHImZWrUoKEUlLJG2XtFPSqjN8L0l3\nJN8/LumSYm0lTZL0gKQdyfvEpHyypO9LOirp8wN+58FkX48lr/MqH/ro4TURM6tWRUNEUg64E1gK\nLACul7RgQLWlwPzktRK4q4S2q4BNETEf2JRsA5wEPg38wVm6dENELExeL5Y0ylFuYlM9h05009cX\naXfFzKwspRyJLAJ2RsSuiDgNrAM6B9TpBNZG3magTdL0Im07gTXJ5zXAtQARcSwifkA+TDKhrame\nvoDDJz2lZWbVpZQQmQnsLtjek5SVUmewtu0RsS/5vB9oL7HPa5KprE9LUoltRrXXbsLodREzqzKj\nYmE9IgIoZS7nhoi4GHhP8vrwmSpJWilpq6StXV1dw9jTkeFbn5hZtaotoc5eYHbB9qykrJQ6dYO0\nPSBpekTsS6a+iq5vRMTe5P2IpK+Sny5be4Z6dwN3A3R0dIz6hYa25Ejkr763g2mtDSW3+9VLZ7No\n3qSR6paZWVGlhMgWYL6keeQDYBnwXwbUWQ/cJmkdcBlwKAmHrkHargdWALcn7/cP1glJtUBbRByU\nVAdcA3yvhP6PehdMbeGiaePZceAIOw4cKanNwaOnOHSi2yFiZqkqGiIR0SPpNmAjkAPuiYhtkm5O\nvl8NbACuBnYCx4EbB2ub7Pp24D5JNwHPAdf1/6akZ4FWoF7StcAHkzobkwDJkQ+QLwxt+KPDhHF1\nfOf33ltWmw9/6SH2Hz41Qj0yMytNKUciRMQG8kFRWLa64HMAt5baNil/CbjyLG3mnqUrl5bS3yxo\nb21kx4GDaXfDzDJuVCysW/mmtTbSdfQUvb62xMxS5BCpUu0TGuntCw4e9ZSWmaXHIVKlprU2ArD/\nUGauyTSzUcghUqVeC5HDDhEzS49DpEq1T8hfT3LAIWJmKXKIVKkpzQ3U1sjTWWaWKodIlaqpEeeN\nb/B0lpmlyiFSxdonNHo6y8xS5RCpYtNaGz2dZWapcohUsfbWRg741idmliKHSBWbNqGRo6d6OHqq\nJ+2umFlGOUSq2PQJvuDQzNLlEKli7ckFh15cN7O0OESqmG99YmZpc4hUsWkTfOsTM0uXQ6SKNdbl\nmDCuzkciZpYah0iVm9ba6CMRM0uNQ6TK+ap1M0uTQ6TKTWtt8HSWmaXGIVLlprU2cvDoKXp6+9Lu\nipllkEOkyrVPaKQvoMuPyTWzFDhEqpyvFTGzNDlEqpyvWjezNDlEqtw03z/LzFJUUohIWiJpu6Sd\nklad4XtJuiP5/nFJlxRrK2mSpAck7UjeJyblkyV9X9JRSZ8f8DuXSnoi2dcdklT50MeGSU311OXE\nft8S3sxSUFusgqQccCdwFbAH2CJpfUQ8VVBtKTA/eV0G3AVcVqTtKmBTRNyehMsq4JPASeDTwFuT\nV6G7gI8CDwEbgCXAtysZ+FiRf0xuIw9uf7GsdnMnN7Fs0ZwR6pWZZUXREAEWATsjYheApHVAJ1AY\nIp3A2ogIYLOkNknTgbmDtO0ErkjarwEeBD4ZEceAH0i6sLATyf5aI2Jzsr0WuJaMhwjAuy+czD8+\n9gK7Dj5TUv3evqC3L1j6tulMGFc3wr0zs7GslBCZCewu2N5D/mijWJ2ZRdq2R8S+5PN+oL2Efuw5\nw29k3md/9ef57K/+fMn1v7ttPyu//AjPHDzGwtltI9gzMxvrRsXCenIEE8O1P0krJW2VtLWrq2u4\ndjtmXDC1GYBnDh5NuSdmVu1KCZG9wOyC7VlJWSl1Bmt7IJmi6p+qKjapvzdpP1g/AIiIuyOiIyI6\npk6dWmS32TNnUjO5GrGr61jaXTGzKldKiGwB5kuaJ6keWAasH1BnPbA8OUtrMXAomaoarO16YEXy\neQVw/2CdSPZ3WNLi5Kys5cXa2JnV19Ywe+I4h4iZDVnRNZGI6JF0G7ARyAH3RMQ2STcn368mf6bU\n1cBO4Dhw42Btk13fDtwn6SbgOeC6/t+U9CzQCtRLuhb4YHJG1y3AvcA48gvqmV9Ur9S8Kc3sOugQ\nMbOhKWVhnYjYQD4oCstWF3wO4NZS2yblLwFXnqXN3LOUb+WNp/1aBS6Y2sK/7XqJvr6gpibzl9uY\nWYVGxcK6nXsXTG3mZHcf+3y7FDMbAodIRs2bkpyh5XURMxsCh0hGvWlqCwC7fJqvmQ2BQySjzhvf\nQHN9zmdomdmQOEQyShLzpvoMLTMbGodIhl0wpYVdXZ7OMrPKOUQybN6UZva+eoKT3b1pd8XMqpRD\nJMMumNpMBDz30vG0u2JmVcohkmGvnaHlKS0zq5BDJMPmJteKeHHdzCrlEMmwloZa2lsbfJqvmVXM\nIZJxF0xp8QWHZlaxkm7AaGPXvKnNfOvxffxk/+GS29TlarhgSjP5O/KbWZY5RDLuLe3j+eqJ51ny\nV/9aVrvPLVtI50I/ndgs6xwiGffr75zNjLZx9PT2ldzmD7/+OJt3vewQMTOHSNY11uW4akF7WW2+\n+vDzPLb71RHqkZlVEy+sW9kWzm5j+/7DHD/dk3ZXzCxlDhEr28LZbfQFPLHnUNpdMbOUOUSsbAtn\ntwF4SsvMHCJWvsktDcyZ1MSjzztEzLLOIWIVWTi7zUciZuYQscosnN3G/sMn2X/oZNpdMbMUOUSs\nIgvn9K+LvJJyT8wsTQ4Rq8jFM1qpz9V4XcQs40oKEUlLJG2XtFPSqjN8L0l3JN8/LumSYm0lTZL0\ngKQdyfvEgu8+ldTfLukXC8ofTMoeS17nVT50G4qG2hw/N6OVR70uYpZpRUNEUg64E1gKLACul7Rg\nQLWlwPzktRK4q4S2q4BNETEf2JRsk3y/DLgYWAL8dbKffjdExMLk9WL5Q7bh8o7ZbTyx51BZt0wx\ns7GllCORRcDOiNgVEaeBdUDngDqdwNrI2wy0SZpepG0nsCb5vAa4tqB8XUSciohngJ3JfmyUWTi7\njRPdvfz0gG8lb5ZVpdw7ayawu2B7D3BZCXVmFmnbHhH7ks/7gf4bOM0ENp9hX/3WSOoGvg58JiKi\nhDHYCOi/6PDXVv+IutrSl9euXTiT//mhi0eqW2Z2Do2KGzBGREgqJQxuiIi9ksaTD5EPA2sHVpK0\nkvy0GnPmzBnWvtrrzp/cxKeWXsQLr54ouc1jew6xbsvzrFp6EY11ueINzGxUKyVE9gKzC7ZnJWWl\n1KkbpO0BSdMjYl8y9dW/vnHW34uI/vcjkr5KfprrDSESEXcDdwN0dHT4SGWESOJj73tTWW3+5add\nLL/nYX6w4yAfKPPuwWY2+pQyB7EFmC9pnqR68ove6wfUWQ8sT87SWgwcSqaqBmu7HliRfF4B3F9Q\nvkxSg6R55BfrH5ZUK2kKgKQ64BrgyQrGbClafMFkxjfU8sBTB9LuipkNg6JHIhHRI+k2YCOQA+6J\niG2Sbk6+Xw1sAK4mvwh+HLhxsLbJrm8H7pN0E/AccF3SZpuk+4CngB7g1ojoldQMbEwCJAd8D/jC\ncPxDsHOnvraG971lKpt+coDeviBX40fsmlUzjfV16Y6Ojti6dWva3bAC9z+2l4+ve4yv//a7uPT8\nSWl3x8zOQNIjEdFRrJ6vWLdz7oq3nEdtjfiup7TMqp5DxM65CePqWHzBZK+LmI0BDhFLxVUL2tnV\ndYyfdflCRbNq5hCxVPSf3vs9H42YVbVRcbGhZc/MtnFcPKOVz27czh2bdpTcbmJzPd+45d1MHd8w\ngr0zs1I5RCw1f/Khi/nOk/tLrt/TF9z7o2f5yubn+MRVbx7BnplZqRwilpqOuZPomFveKb7Pv3yc\nr2x+jt++4k2+bYrZKOA1EasqN10+j5eOnWb9Yy+k3RUzwyFiVeYX3jSZi6aN554fPsNYv1DWrBo4\nRKyqSOIj757HT/Yf4Uc/eynt7phlnkPEqs6HFs5gSks9X/rBM2l3xSzzvLBuVaexLscNl53P5zbt\n4M3/49slt6utEZ++ZgHXL/IzZsyGi0PEqtJN75lHAKd7Sn+++0PPvMT/+uZTXH7hFGZPahq5zpll\niEPEqlJrYx3/tcxrRV549QRX/cU/8+n7n+RvfvOdSL4NvdlQeU3EMmNG2zh+/4Nv4cHtXfzT4/vS\n7o7ZmOAjEcuUFb8wl288upc/+eY2Fs5uo6m+9AsWW8fVUZfz37vMCjlELFNyNeJ//+e38aHP/4D3\nfPb7ZbWdO7mJr33sXbS3No5Q78yqj0PEMuetMyfwtY+9i6f3HS65zemePv7ygZ+y4p6Hue/md9Ha\nWDeCPTSrHg4Ry6R3zp3EO8u8b9eb28fzkXu3sHLtVtZ8ZBENtb53l5lDxKxE733zVP78197OJ772\n71y3+t+YVcZpwk11OW57/4WcP7l5BHtodu45RMzK8MvvmMXRU72s/dGz/KSM6bD9h07ynW37+cvr\nFr72QC6zsUBj/SZ2HR0dsXXr1rS7YRm3++Xj/PbfPsKTew9z8/vexOUXTimr/cUzWpnYXD9CvTN7\nI0mPRERH0XoOEbNz42R3L398/za+tnV32W3HN9Ry8xVv4iPvnse4Mk5LNquUQyThELHR5ul9hzl6\nqqfk+qe6+1jzb8/ywFMHmNbayPt/7jxqyrjYfmJTPZ0LZ3DheePL76xl1rCGiKQlwOeAHPDFiLh9\nwPdKvr8aOA78ZkT8eLC2kiYBXwPmAs8C10XEK8l3nwJuAnqB342IjUn5pcC9wDhgA/DxKDIAh4iN\nFVuefZk/37idn714tKx2r57oprcveMecNpa+dRrjyngiZE2NeNvMCVw8YwK5cpLLqt6whYikHPBT\n4CpgD7AFuD4iniqoczXwO+RD5DLgcxFx2WBtJX0WeDkibpe0CpgYEZ+UtAD4O2ARMAP4HvDmiOiV\n9DDwu8BD5EPkjogY9DauDhHLuq4jp/jHR/dy39bd7CgzgPq1NdWxeN5kJrWUty4zpbmeBTNaWTB9\nAtPbGiknhmokahxcqSk1REo5O2sRsDMidiU7Xgd0Ak8V1OkE1iZHBZsltUmaTv4o42xtO4ErkvZr\ngAeBTybl6yLiFPCMpJ3AIknPAq0RsTnZ11rgWqD0e4GbZdDU8Q189L0X8Fvvmccrx7vpK2MK+2R3\nL4889wo/2HGQh555meOne8v45eCV4/mjoErUCKZPGMecSU1Mb2uktsxAaW2sY+r4Bqa0NNBYxtEX\nQF1OtI6ro7Wxjqb6HOXcq1OIxvoamutrGVeXG/NBWEqIzAQKVwL3kD/aKFZnZpG27RHRfxe8/UD/\neY8zgc1n2Fd38nlguZmVQBKTKjjDa9bEJjoXVva/2snuXn564AhPvXCYriOnymvb08veV06w+5UT\nPLTr5bLCry+CQye6Odld+qMCRovaGtFQW0NDXa7sKUQBdbka6nKiLlfDN3/n8rIDtFyj4jqRiAhJ\nw7bCL2klsBJgzhw/gMgsLY11Od4+q423z2o7578dERw73UvXkVN095YXJqe6+zhyspvDJ7vLPPqC\nvoAT3b0cP9XD8dO9lPUHWwQ9fcGpnj5O9fRSZreJCLp7g+7ePrp7+8o+eqtEKSGyF5hdsD0rKSul\nTt0gbQ9Imh4R+5KprxeL7Gtv8nmwfgAQEXcDd0N+TWSwwZnZ2CSJloZaWhpGxd+Vx6xS7mu9BZgv\naZ6kemAZsH5AnfXAcuUtBg4lU1WDtV0PrEg+rwDuLyhfJqlB0jxgPvBwsr/DkhYnZ4MtL2hjZmYp\nKBrREdEj6TZgI/nTdO+JiG2Sbk6+X03+TKmrgZ3kT/G9cbC2ya5vB+6TdBPwHHBd0mabpPvIL773\nALdGRP/x5C28forvt/GiuplZqnyxoZmZvUGpp/j6MW1mZlYxh4iZmVXMIWJmZhVziJiZWcUcImZm\nVrExf3aWpC7ypxBXYgpwcBi7Uw2yOGbI5rizOGbI5rgrGfP5ETG1WKUxHyJDIWlrKae4jSVZHDNk\nc9xZHDNkc9wjOWZPZ5mZWcUcImZmVjGHyODuTrsDKcjimCGb487imCGb4x6xMXtNxMzMKuYjETMz\nq5hD5AwkLZG0XdLO5PnvY5Kk2ZK+L+kpSdskfTwpnyTpAUk7kveJafd1uEnKSXpU0j8l21kYc5uk\nv5f0E0lPS3rXWB+3pE8k/20/KenvJDWOxTFLukfSi5KeLCg76zglfSr58227pF8cym87RAaQlAPu\nBJYCC4DrJS1It1cjpgf4/YhYACwGbk3GugrYFBHzgU3J9ljzceDpgu0sjPlzwHci4iLg58mPf8yO\nW9JM4HeBjoh4K/nHUSxjbI75XmDJgLIzjjP5f3wZcHHS5q+TP/cq4hB5o0XAzojYFRGngXVAZ8p9\nGhERsS8ifpx8PkL+D5WZ5Me7Jqm2Brg2nR6ODEmzgP8EfLGgeKyPeQLwXuBLABFxOiJeZYyPm/wz\nk8ZJqgWagBcYg2OOiH8BXh5QfLZxdgLrIuJURDxD/jlQiyr9bYfIG80Edhds70nKxjRJc4F3AA8B\n7cmTJAH2A+0pdWuk/BXwh0DhE6zH+pjnAV3A3yTTeF+U1MwYHndE7AX+D/A8sI/8E1e/yxge8wBn\nG+ew/hnnEDEktQBfB34vIg4Xfhf50/fGzCl8kq4BXoyIR85WZ6yNOVELXALcFRHvAI4xYBpnrI07\nWQPoJB+gM4BmSb9RWGesjflsRnKcDpE32gvMLtielZSNSZLqyAfI30bEPyTFByRNT76fDryYVv9G\nwLuBD0l6lvxU5fslfYWxPWbI/21zT0Q8lGz/PflQGcvj/gDwTER0RUQ38A/ALzC2x1zobOMc1j/j\nHCJvtAWYL2mepHryC1DrU+7TiJAk8nPkT0fEXxR8tR5YkXxeAdx/rvs2UiLiUxExKyLmkv93+/8i\n4jcYw2MGiIj9wG5Jb0mKrgSeYmyP+3lgsaSm5L/1K8mv+43lMRc62zjXA8skNUiaB8wHHq70R3yx\n4RlIupr8vHkOuCci/jTlLo0ISZcD/wo8wevrA/+N/LrIfcAc8ndAvi4iBi7aVT1JVwB/EBHXSJrM\nGB+zpIUPZrJFAAAAeklEQVTkTyaoB3YBN5L/i+SYHbekPwF+nfyZiI8CvwW0MMbGLOnvgCvI3633\nAPDHwD9ylnFK+u/AR8j/c/m9iPh2xb/tEDEzs0p5OsvMzCrmEDEzs4o5RMzMrGIOETMzq5hDxMzM\nKuYQMTOzijlEzMysYg4RMzOr2P8HX/+ojjzaGyIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7367164210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = []\n",
    "for i in range(100):\n",
    "    lr.append(step_decay(i))\n",
    "plt.plot(np.arange(100), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_arr = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace top layer of DenseNet with a FC layer (1024) with batch normalization and ReLU and a FC layer (128). Train with all layers as learnable for 50 epochs with learning rate decay 1e-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7775235341860272509\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3580690432\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 8672994543831254245\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for the model were loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/cpu:0'):\n",
    "# https://keras.io/applications/#fine-tune-inceptionv3-on-a-new-set-of-classes\n",
    "i = 0\n",
    "image_dim = (224, 224, 3)\n",
    "base_model = densenet.DenseNetImageNet121(image_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 112, 112, 64)  9408        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 112, 112, 64)  256         conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 112, 112, 64)  0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 56, 56, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 56, 56, 64)    256         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 56, 56, 64)    0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 56, 56, 128)   8192        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 56, 56, 128)   512         conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 56, 56, 128)   0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 56, 56, 32)    36864       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 56, 56, 96)    0           max_pooling2d_1[0][0]            \n",
      "                                                                   conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 56, 56, 96)    384         concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 56, 56, 96)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 56, 56, 128)   12288       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 56, 56, 128)   512         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 56, 56, 128)   0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 56, 56, 32)    36864       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 56, 56, 128)   0           concatenate_1[0][0]              \n",
      "                                                                   conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 56, 56, 128)   512         concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 56, 56, 128)   0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 56, 56, 128)   16384       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 56, 56, 128)   512         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 56, 56, 128)   0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 56, 56, 32)    36864       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 56, 56, 160)   0           concatenate_2[0][0]              \n",
      "                                                                   conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 56, 56, 160)   640         concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 56, 56, 160)   0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 56, 56, 128)   20480       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 56, 56, 128)   512         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 56, 56, 128)   0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 56, 56, 32)    36864       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 56, 56, 192)   0           concatenate_3[0][0]              \n",
      "                                                                   conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 56, 56, 192)   768         concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 56, 56, 192)   0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 56, 56, 128)   24576       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, 56, 56, 128)   512         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 56, 56, 128)   0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 56, 56, 32)    36864       activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 56, 56, 224)   0           concatenate_4[0][0]              \n",
      "                                                                   conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, 56, 56, 224)   896         concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 56, 56, 224)   0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 56, 56, 128)   28672       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, 56, 56, 128)   512         conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 56, 56, 128)   0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 56, 56, 32)    36864       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 56, 56, 256)   0           concatenate_5[0][0]              \n",
      "                                                                   conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, 56, 56, 256)   1024        concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 56, 56, 256)   0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 56, 56, 128)   32768       activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 28, 28, 128)   0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, 28, 28, 128)   512         average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 28, 28, 128)   0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 28, 28, 128)   16384       activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, 28, 28, 128)   512         conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 28, 28, 128)   0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 28, 28, 32)    36864       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 28, 28, 160)   0           average_pooling2d_1[0][0]        \n",
      "                                                                   conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, 28, 28, 160)   640         concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 28, 28, 160)   0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 28, 28, 128)   20480       activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 28, 28, 128)   512         conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 28, 28, 128)   0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 28, 28, 32)    36864       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 28, 28, 192)   0           concatenate_7[0][0]              \n",
      "                                                                   conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 28, 28, 192)   768         concatenate_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 28, 28, 192)   0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 28, 28, 128)   24576       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 28, 28, 128)   512         conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 28, 28, 128)   0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 28, 28, 32)    36864       activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)      (None, 28, 28, 224)   0           concatenate_8[0][0]              \n",
      "                                                                   conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 28, 28, 224)   896         concatenate_9[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 28, 28, 224)   0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 28, 28, 128)   28672       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 28, 28, 128)   512         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 28, 28, 128)   0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 28, 28, 32)    36864       activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)     (None, 28, 28, 256)   0           concatenate_9[0][0]              \n",
      "                                                                   conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 28, 28, 256)   1024        concatenate_10[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 28, 28, 256)   0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 28, 28, 128)   32768       activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 28, 28, 128)   512         conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 28, 28, 128)   0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 28, 28, 32)    36864       activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)     (None, 28, 28, 288)   0           concatenate_10[0][0]             \n",
      "                                                                   conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 28, 28, 288)   1152        concatenate_11[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 28, 28, 288)   0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 28, 28, 128)   36864       activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 28, 28, 128)   512         conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 28, 28, 128)   0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 28, 28, 32)    36864       activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)     (None, 28, 28, 320)   0           concatenate_11[0][0]             \n",
      "                                                                   conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 28, 28, 320)   1280        concatenate_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 28, 28, 320)   0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 28, 28, 128)   40960       activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 28, 28, 128)   512         conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 28, 28, 128)   0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 28, 28, 32)    36864       activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)     (None, 28, 28, 352)   0           concatenate_12[0][0]             \n",
      "                                                                   conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 28, 28, 352)   1408        concatenate_13[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 28, 28, 352)   0           batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 28, 28, 128)   45056       activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 28, 28, 128)   512         conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 28, 28, 128)   0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 28, 28, 32)    36864       activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)     (None, 28, 28, 384)   0           concatenate_13[0][0]             \n",
      "                                                                   conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 28, 28, 384)   1536        concatenate_14[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 28, 28, 384)   0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 28, 28, 128)   49152       activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 28, 28, 128)   512         conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 28, 28, 128)   0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 28, 28, 32)    36864       activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)     (None, 28, 28, 416)   0           concatenate_14[0][0]             \n",
      "                                                                   conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 28, 28, 416)   1664        concatenate_15[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 28, 28, 416)   0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 28, 28, 128)   53248       activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 28, 28, 128)   512         conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 28, 28, 128)   0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 28, 28, 32)    36864       activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)     (None, 28, 28, 448)   0           concatenate_15[0][0]             \n",
      "                                                                   conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, 28, 28, 448)   1792        concatenate_16[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 28, 28, 448)   0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 28, 28, 128)   57344       activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, 28, 28, 128)   512         conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 28, 28, 128)   0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 28, 28, 32)    36864       activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)     (None, 28, 28, 480)   0           concatenate_16[0][0]             \n",
      "                                                                   conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, 28, 28, 480)   1920        concatenate_17[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 28, 28, 480)   0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 28, 28, 128)   61440       activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, 28, 28, 128)   512         conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 28, 28, 128)   0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 28, 28, 32)    36864       activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)     (None, 28, 28, 512)   0           concatenate_17[0][0]             \n",
      "                                                                   conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, 28, 28, 512)   2048        concatenate_18[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 28, 28, 512)   0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 28, 28, 256)   131072      activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, 14, 14, 256)   0           conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, 14, 14, 256)   1024        average_pooling2d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 14, 14, 256)   0           batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 14, 14, 128)   32768       activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, 14, 14, 128)   512         conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 14, 14, 128)   0           batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, 14, 14, 32)    36864       activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)     (None, 14, 14, 288)   0           average_pooling2d_2[0][0]        \n",
      "                                                                   conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, 14, 14, 288)   1152        concatenate_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 14, 14, 288)   0           batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, 14, 14, 128)   36864       activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, 14, 14, 128)   512         conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 14, 14, 128)   0           batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, 14, 14, 32)    36864       activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)     (None, 14, 14, 320)   0           concatenate_19[0][0]             \n",
      "                                                                   conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, 14, 14, 320)   1280        concatenate_20[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 14, 14, 320)   0           batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, 14, 14, 128)   40960       activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, 14, 14, 128)   512         conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 14, 14, 128)   0           batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, 14, 14, 32)    36864       activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)     (None, 14, 14, 352)   0           concatenate_20[0][0]             \n",
      "                                                                   conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, 14, 14, 352)   1408        concatenate_21[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 14, 14, 352)   0           batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, 14, 14, 128)   45056       activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, 14, 14, 128)   512         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 14, 14, 128)   0           batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, 14, 14, 32)    36864       activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)     (None, 14, 14, 384)   0           concatenate_21[0][0]             \n",
      "                                                                   conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, 14, 14, 384)   1536        concatenate_22[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 14, 14, 384)   0           batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, 14, 14, 128)   49152       activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, 14, 14, 128)   512         conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 14, 14, 128)   0           batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, 14, 14, 32)    36864       activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)     (None, 14, 14, 416)   0           concatenate_22[0][0]             \n",
      "                                                                   conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, 14, 14, 416)   1664        concatenate_23[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, 14, 14, 416)   0           batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, 14, 14, 128)   53248       activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, 14, 14, 128)   512         conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, 14, 14, 128)   0           batch_normalization_51[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, 14, 14, 32)    36864       activation_51[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)     (None, 14, 14, 448)   0           concatenate_23[0][0]             \n",
      "                                                                   conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, 14, 14, 448)   1792        concatenate_24[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, 14, 14, 448)   0           batch_normalization_52[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, 14, 14, 128)   57344       activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNor (None, 14, 14, 128)   512         conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, 14, 14, 128)   0           batch_normalization_53[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, 14, 14, 32)    36864       activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)     (None, 14, 14, 480)   0           concatenate_24[0][0]             \n",
      "                                                                   conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNor (None, 14, 14, 480)   1920        concatenate_25[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, 14, 14, 480)   0           batch_normalization_54[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, 14, 14, 128)   61440       activation_54[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNor (None, 14, 14, 128)   512         conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, 14, 14, 128)   0           batch_normalization_55[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, 14, 14, 32)    36864       activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)     (None, 14, 14, 512)   0           concatenate_25[0][0]             \n",
      "                                                                   conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNor (None, 14, 14, 512)   2048        concatenate_26[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, 14, 14, 512)   0           batch_normalization_56[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, 14, 14, 128)   65536       activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, 14, 14, 128)   512         conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, 14, 14, 128)   0           batch_normalization_57[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, 14, 14, 32)    36864       activation_57[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)     (None, 14, 14, 544)   0           concatenate_26[0][0]             \n",
      "                                                                   conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, 14, 14, 544)   2176        concatenate_27[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, 14, 14, 544)   0           batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, 14, 14, 128)   69632       activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, 14, 14, 128)   512         conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, 14, 14, 128)   0           batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, 14, 14, 32)    36864       activation_59[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)     (None, 14, 14, 576)   0           concatenate_27[0][0]             \n",
      "                                                                   conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, 14, 14, 576)   2304        concatenate_28[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, 14, 14, 576)   0           batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, 14, 14, 128)   73728       activation_60[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, 14, 14, 128)   512         conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, 14, 14, 128)   0           batch_normalization_61[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)               (None, 14, 14, 32)    36864       activation_61[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)     (None, 14, 14, 608)   0           concatenate_28[0][0]             \n",
      "                                                                   conv2d_61[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, 14, 14, 608)   2432        concatenate_29[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, 14, 14, 608)   0           batch_normalization_62[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)               (None, 14, 14, 128)   77824       activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, 14, 14, 128)   512         conv2d_62[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, 14, 14, 128)   0           batch_normalization_63[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)               (None, 14, 14, 32)    36864       activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)     (None, 14, 14, 640)   0           concatenate_29[0][0]             \n",
      "                                                                   conv2d_63[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, 14, 14, 640)   2560        concatenate_30[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, 14, 14, 640)   0           batch_normalization_64[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)               (None, 14, 14, 128)   81920       activation_64[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, 14, 14, 128)   512         conv2d_64[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, 14, 14, 128)   0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)               (None, 14, 14, 32)    36864       activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)     (None, 14, 14, 672)   0           concatenate_30[0][0]             \n",
      "                                                                   conv2d_65[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, 14, 14, 672)   2688        concatenate_31[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, 14, 14, 672)   0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)               (None, 14, 14, 128)   86016       activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, 14, 14, 128)   512         conv2d_66[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, 14, 14, 128)   0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)               (None, 14, 14, 32)    36864       activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)     (None, 14, 14, 704)   0           concatenate_31[0][0]             \n",
      "                                                                   conv2d_67[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, 14, 14, 704)   2816        concatenate_32[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, 14, 14, 704)   0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)               (None, 14, 14, 128)   90112       activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, 14, 14, 128)   512         conv2d_68[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, 14, 14, 128)   0           batch_normalization_69[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, 14, 14, 32)    36864       activation_69[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)     (None, 14, 14, 736)   0           concatenate_32[0][0]             \n",
      "                                                                   conv2d_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, 14, 14, 736)   2944        concatenate_33[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, 14, 14, 736)   0           batch_normalization_70[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, 14, 14, 128)   94208       activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, 14, 14, 128)   512         conv2d_70[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, 14, 14, 128)   0           batch_normalization_71[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, 14, 14, 32)    36864       activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)     (None, 14, 14, 768)   0           concatenate_33[0][0]             \n",
      "                                                                   conv2d_71[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, 14, 14, 768)   3072        concatenate_34[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, 14, 14, 768)   0           batch_normalization_72[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, 14, 14, 128)   98304       activation_72[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, 14, 14, 128)   512         conv2d_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, 14, 14, 128)   0           batch_normalization_73[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, 14, 14, 32)    36864       activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)     (None, 14, 14, 800)   0           concatenate_34[0][0]             \n",
      "                                                                   conv2d_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, 14, 14, 800)   3200        concatenate_35[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, 14, 14, 800)   0           batch_normalization_74[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, 14, 14, 128)   102400      activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, 14, 14, 128)   512         conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, 14, 14, 128)   0           batch_normalization_75[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, 14, 14, 32)    36864       activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)     (None, 14, 14, 832)   0           concatenate_35[0][0]             \n",
      "                                                                   conv2d_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, 14, 14, 832)   3328        concatenate_36[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, 14, 14, 832)   0           batch_normalization_76[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, 14, 14, 128)   106496      activation_76[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, 14, 14, 128)   512         conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, 14, 14, 128)   0           batch_normalization_77[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, 14, 14, 32)    36864       activation_77[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)     (None, 14, 14, 864)   0           concatenate_36[0][0]             \n",
      "                                                                   conv2d_77[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, 14, 14, 864)   3456        concatenate_37[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, 14, 14, 864)   0           batch_normalization_78[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, 14, 14, 128)   110592      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, 14, 14, 128)   512         conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, 14, 14, 128)   0           batch_normalization_79[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, 14, 14, 32)    36864       activation_79[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)     (None, 14, 14, 896)   0           concatenate_37[0][0]             \n",
      "                                                                   conv2d_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, 14, 14, 896)   3584        concatenate_38[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, 14, 14, 896)   0           batch_normalization_80[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, 14, 14, 128)   114688      activation_80[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, 14, 14, 128)   512         conv2d_80[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, 14, 14, 128)   0           batch_normalization_81[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, 14, 14, 32)    36864       activation_81[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)     (None, 14, 14, 928)   0           concatenate_38[0][0]             \n",
      "                                                                   conv2d_81[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, 14, 14, 928)   3712        concatenate_39[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, 14, 14, 928)   0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, 14, 14, 128)   118784      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, 14, 14, 128)   512         conv2d_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, 14, 14, 128)   0           batch_normalization_83[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, 14, 14, 32)    36864       activation_83[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)     (None, 14, 14, 960)   0           concatenate_39[0][0]             \n",
      "                                                                   conv2d_83[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, 14, 14, 960)   3840        concatenate_40[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, 14, 14, 960)   0           batch_normalization_84[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, 14, 14, 128)   122880      activation_84[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, 14, 14, 128)   512         conv2d_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, 14, 14, 128)   0           batch_normalization_85[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, 14, 14, 32)    36864       activation_85[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)     (None, 14, 14, 992)   0           concatenate_40[0][0]             \n",
      "                                                                   conv2d_85[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, 14, 14, 992)   3968        concatenate_41[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, 14, 14, 992)   0           batch_normalization_86[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, 14, 14, 128)   126976      activation_86[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, 14, 14, 128)   512         conv2d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, 14, 14, 128)   0           batch_normalization_87[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, 14, 14, 32)    36864       activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)     (None, 14, 14, 1024)  0           concatenate_41[0][0]             \n",
      "                                                                   conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, 14, 14, 1024)  4096        concatenate_42[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, 14, 14, 1024)  0           batch_normalization_88[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, 14, 14, 512)   524288      activation_88[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, 7, 7, 512)     0           conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, 7, 7, 512)     2048        average_pooling2d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, 7, 7, 512)     0           batch_normalization_89[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, 7, 7, 128)     65536       activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, 7, 7, 128)     512         conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, 7, 7, 128)     0           batch_normalization_90[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, 7, 7, 32)      36864       activation_90[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)     (None, 7, 7, 544)     0           average_pooling2d_3[0][0]        \n",
      "                                                                   conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, 7, 7, 544)     2176        concatenate_43[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, 7, 7, 544)     0           batch_normalization_91[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, 7, 7, 128)     69632       activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, 7, 7, 128)     512         conv2d_91[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, 7, 7, 128)     0           batch_normalization_92[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, 7, 7, 32)      36864       activation_92[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)     (None, 7, 7, 576)     0           concatenate_43[0][0]             \n",
      "                                                                   conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, 7, 7, 576)     2304        concatenate_44[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, 7, 7, 576)     0           batch_normalization_93[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, 7, 7, 128)     73728       activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, 7, 7, 128)     512         conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, 7, 7, 128)     0           batch_normalization_94[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, 7, 7, 32)      36864       activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)     (None, 7, 7, 608)     0           concatenate_44[0][0]             \n",
      "                                                                   conv2d_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, 7, 7, 608)     2432        concatenate_45[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, 7, 7, 608)     0           batch_normalization_95[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, 7, 7, 128)     77824       activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, 7, 7, 128)     512         conv2d_95[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, 7, 7, 128)     0           batch_normalization_96[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, 7, 7, 32)      36864       activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)     (None, 7, 7, 640)     0           concatenate_45[0][0]             \n",
      "                                                                   conv2d_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, 7, 7, 640)     2560        concatenate_46[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, 7, 7, 640)     0           batch_normalization_97[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, 7, 7, 128)     81920       activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, 7, 7, 128)     512         conv2d_97[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, 7, 7, 128)     0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, 7, 7, 32)      36864       activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)     (None, 7, 7, 672)     0           concatenate_46[0][0]             \n",
      "                                                                   conv2d_98[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, 7, 7, 672)     2688        concatenate_47[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, 7, 7, 672)     0           batch_normalization_99[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, 7, 7, 128)     86016       activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, 7, 7, 128)     512         conv2d_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, 7, 7, 128)     0           batch_normalization_100[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, 7, 7, 32)      36864       activation_100[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)     (None, 7, 7, 704)     0           concatenate_47[0][0]             \n",
      "                                                                   conv2d_100[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, 7, 7, 704)     2816        concatenate_48[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, 7, 7, 704)     0           batch_normalization_101[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, 7, 7, 128)     90112       activation_101[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, 7, 7, 128)     512         conv2d_101[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, 7, 7, 128)     0           batch_normalization_102[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, 7, 7, 32)      36864       activation_102[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)     (None, 7, 7, 736)     0           concatenate_48[0][0]             \n",
      "                                                                   conv2d_102[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, 7, 7, 736)     2944        concatenate_49[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, 7, 7, 736)     0           batch_normalization_103[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)              (None, 7, 7, 128)     94208       activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, 7, 7, 128)     512         conv2d_103[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, 7, 7, 128)     0           batch_normalization_104[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)              (None, 7, 7, 32)      36864       activation_104[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)     (None, 7, 7, 768)     0           concatenate_49[0][0]             \n",
      "                                                                   conv2d_104[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNo (None, 7, 7, 768)     3072        concatenate_50[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, 7, 7, 768)     0           batch_normalization_105[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)              (None, 7, 7, 128)     98304       activation_105[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchNo (None, 7, 7, 128)     512         conv2d_105[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, 7, 7, 128)     0           batch_normalization_106[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)              (None, 7, 7, 32)      36864       activation_106[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)     (None, 7, 7, 800)     0           concatenate_50[0][0]             \n",
      "                                                                   conv2d_106[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchNo (None, 7, 7, 800)     3200        concatenate_51[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, 7, 7, 800)     0           batch_normalization_107[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)              (None, 7, 7, 128)     102400      activation_107[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchNo (None, 7, 7, 128)     512         conv2d_107[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, 7, 7, 128)     0           batch_normalization_108[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)              (None, 7, 7, 32)      36864       activation_108[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)     (None, 7, 7, 832)     0           concatenate_51[0][0]             \n",
      "                                                                   conv2d_108[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchNo (None, 7, 7, 832)     3328        concatenate_52[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, 7, 7, 832)     0           batch_normalization_109[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)              (None, 7, 7, 128)     106496      activation_109[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchNo (None, 7, 7, 128)     512         conv2d_109[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, 7, 7, 128)     0           batch_normalization_110[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)              (None, 7, 7, 32)      36864       activation_110[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)     (None, 7, 7, 864)     0           concatenate_52[0][0]             \n",
      "                                                                   conv2d_110[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchNo (None, 7, 7, 864)     3456        concatenate_53[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, 7, 7, 864)     0           batch_normalization_111[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, 7, 7, 128)     110592      activation_111[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchNo (None, 7, 7, 128)     512         conv2d_111[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, 7, 7, 128)     0           batch_normalization_112[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)              (None, 7, 7, 32)      36864       activation_112[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)     (None, 7, 7, 896)     0           concatenate_53[0][0]             \n",
      "                                                                   conv2d_112[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, 7, 7, 896)     3584        concatenate_54[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, 7, 7, 896)     0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, 7, 7, 128)     114688      activation_113[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, 7, 7, 128)     512         conv2d_113[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, 7, 7, 128)     0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, 7, 7, 32)      36864       activation_114[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)     (None, 7, 7, 928)     0           concatenate_54[0][0]             \n",
      "                                                                   conv2d_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNo (None, 7, 7, 928)     3712        concatenate_55[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, 7, 7, 928)     0           batch_normalization_115[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, 7, 7, 128)     118784      activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNo (None, 7, 7, 128)     512         conv2d_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, 7, 7, 128)     0           batch_normalization_116[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, 7, 7, 32)      36864       activation_116[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)     (None, 7, 7, 960)     0           concatenate_55[0][0]             \n",
      "                                                                   conv2d_116[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNo (None, 7, 7, 960)     3840        concatenate_56[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, 7, 7, 960)     0           batch_normalization_117[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, 7, 7, 128)     122880      activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNo (None, 7, 7, 128)     512         conv2d_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, 7, 7, 128)     0           batch_normalization_118[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, 7, 7, 32)      36864       activation_118[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)     (None, 7, 7, 992)     0           concatenate_56[0][0]             \n",
      "                                                                   conv2d_118[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNo (None, 7, 7, 992)     3968        concatenate_57[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, 7, 7, 992)     0           batch_normalization_119[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)              (None, 7, 7, 128)     126976      activation_119[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, 7, 7, 128)     512         conv2d_119[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, 7, 7, 128)     0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)              (None, 7, 7, 32)      36864       activation_120[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)     (None, 7, 7, 1024)    0           concatenate_57[0][0]             \n",
      "                                                                   conv2d_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, 7, 7, 1024)    4096        concatenate_58[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, 7, 7, 1024)    0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 1024)          0           activation_121[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1000)          1025000     global_average_pooling2d_1[0][0] \n",
      "====================================================================================================\n",
      "Total params: 8,062,504\n",
      "Trainable params: 7,978,856\n",
      "Non-trainable params: 83,648\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = Sequential()\n",
    "# new_input = Input(input_shape=(128,64,3), name='new_input')\n",
    "# test.add(input_1)\n",
    "# test.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_input = Input(shape=(128,64,3), name='new_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.outputs = [base_model.layers[-2].output]\n",
    "base_model.layers[-1].outbound_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://datascience.stackexchange.com/questions/21610/prepending-input-layer-to-pre-trained-model\n",
    "x = base_model.outputs[0] # (new_input)\n",
    "x = Dense(1024)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "predictions = Dense(128)(x)\n",
    "\n",
    "pre_trinet = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "pre_trinet.compile(loss=triplet_loss, optimizer=Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trinet = Model(inputs=new_input, outputs=pre_trinet(new_input))\n",
    "trinet.compile(loss=triplet_loss, optimizer=Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in trinet.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "new_input (InputLayer)       (None, 128, 64, 3)        0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 128)               8222400   \n",
      "=================================================================\n",
      "Total params: 8,222,400\n",
      "Trainable params: 8,136,704\n",
      "Non-trainable params: 85,696\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trinet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trinet = load_model('/home/albert/github/tensorflow/test_triplet_5k_margin_0.5.h5', \n",
    "                    custom_objects={'triplet_loss':triplet_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 73s - loss: -3674986060.8000    \n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 67s - loss: -3800014796.8000    \n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 66s - loss: -3922372305.9200    \n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 66s - loss: -4051510272.0000    \n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 66s - loss: -4167098956.8000    \n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 66s - loss: -4288283609.6000    \n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 66s - loss: -4430707660.8000    \n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 66s - loss: -4546716866.5600    \n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 66s - loss: -4676911278.0800    \n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 66s - loss: -4804002595.8400    \n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 66s - loss: -4950028252.1600    \n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 66s - loss: -5095468641.2800    \n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 66s - loss: -5239116825.6000    \n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 66s - loss: -5363491025.9200    \n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 66s - loss: -5505877017.6000    \n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 66s - loss: -5658144117.7600    \n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 66s - loss: -5804465203.2000    \n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 66s - loss: -5950988426.2400    \n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 66s - loss: -6073212579.8400    \n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 66s - loss: -6232615982.0800    \n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 66s - loss: -6389871022.0800    \n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 66s - loss: -6498051706.8800    \n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 66s - loss: -6683233029.1200    \n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 66s - loss: -6836969507.8400    \n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 66s - loss: -7014585221.1200    \n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 66s - loss: -7158362024.9600    \n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 66s - loss: -7316628736.0000    \n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 66s - loss: -7487553602.5600    \n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 66s - loss: -7640468981.7600    \n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 66s - loss: -7806760289.2800    \n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 66s - loss: -7975193062.4000    \n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 66s - loss: -8146462126.0800    \n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 66s - loss: -8307510763.5200    \n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 66s - loss: -8482764103.6800    \n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 66s - loss: -8661660057.6000    \n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 66s - loss: -8828530380.8000    \n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 66s - loss: -9013784115.2000    \n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 66s - loss: -9196302643.2000    \n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 66s - loss: -9366073405.4400    \n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 66s - loss: -9539629680.6400    \n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 66s - loss: -9730964193.2800    \n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 66s - loss: -9904214865.9200    \n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 66s - loss: -10080589383.6800    \n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 66s - loss: -10244369264.6400    \n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 66s - loss: -10430475796.4800    \n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 66s - loss: -10648007004.1600    \n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 66s - loss: -10820517601.2800    \n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 66s - loss: -11010256240.6400    \n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 66s - loss: -11198935470.0800    \n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 66s - loss: -11400591994.8800    \n",
      "0.326\n",
      "0.296\n",
      "0.335\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 67s - loss: -11605067868.1600    \n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 65s - loss: -11797119969.2800    \n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 64s - loss: -12000499066.8800    \n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 65s - loss: -12190833448.9600    \n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 65s - loss: -12396770324.4800    \n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 65s - loss: -12594719129.6000    \n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 65s - loss: -12803449630.7200    \n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 66s - loss: -13008576634.8800    \n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 66s - loss: -13189891379.2000    \n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 66s - loss: -13419650160.6400    \n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 66s - loss: -13573261803.5200    \n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 65s - loss: -13766015631.3600    \n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 66s - loss: -13990792314.8800    \n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 66s - loss: -14222897735.6800    \n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 66s - loss: -14434164695.0400    \n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 65s - loss: -14672195932.1600    \n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 66s - loss: -14789965035.5200    \n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 65s - loss: -15067844556.8000    \n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 66s - loss: -15290811607.0400    \n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 65s - loss: -15538572482.5600    \n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 65s - loss: -15751666769.9200    \n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 66s - loss: -15956685731.8400    \n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 66s - loss: -16157098895.3600    \n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 66s - loss: -16418650992.6400    \n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 65s - loss: -16660310927.3600    \n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 65s - loss: -16850605537.2800    \n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 66s - loss: -17135413882.8800    \n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 66s - loss: -17372509122.5600    \n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 66s - loss: -17604078202.8800    \n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 66s - loss: -17835737497.6000    \n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 66s - loss: -18077782364.1600    \n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 66s - loss: -18320115732.4800    \n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 66s - loss: -18557398487.0400    \n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 66s - loss: -18799553024.0000    \n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 65s - loss: -19046759751.6800    \n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 66s - loss: -19300903219.2000    \n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 66s - loss: -19539465871.3600    \n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 66s - loss: -19789390561.2800    \n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 66s - loss: -20054714777.6000    \n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 66s - loss: -20299406479.3600    \n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 66s - loss: -20523172167.6800    \n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 66s - loss: -20787601018.8800    \n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 65s - loss: -21000884264.9600    \n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 65s - loss: -21261945098.2400    \n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 65s - loss: -21545962106.8800    \n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 66s - loss: -21748549488.6400    \n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 65s - loss: -22062898032.6400    \n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 66s - loss: -22272064921.6000    \n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 65s - loss: -22544645918.7200    \n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 66s - loss: -22744793067.5200    \n",
      "0.327\n",
      "0.327\n",
      "0.335\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 67s - loss: -23082128404.4800    \n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 67s - loss: -23364979056.6400    \n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 65s - loss: -23626563153.9200    \n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 65s - loss: -23901575741.4400    \n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 66s - loss: -24203880693.7600    \n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 65s - loss: -24462165647.3600    \n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 66s - loss: -24724171345.9200    \n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 65s - loss: -24946648555.5200    \n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 65s - loss: -25250927226.8800    \n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 66s - loss: -25507203235.8400    \n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 66s - loss: -25822827089.9200    \n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 65s - loss: -26104986337.2800    \n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 65s - loss: -26349389148.1600    \n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 65s - loss: -26659519692.8000    \n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 65s - loss: -26931440189.4400    \n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 66s - loss: -27177002577.9200    \n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 65s - loss: -27461219184.6400    \n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 66s - loss: -27769882050.5600    \n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 65s - loss: -28048627875.8400    \n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 66s - loss: -28381168353.2800    \n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 66s - loss: -28667769937.9200    \n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 66s - loss: -28903518740.4800    \n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 66s - loss: -29272339845.1200    \n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 66s - loss: -29546325299.2000    \n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 65s - loss: -29835420569.6000    \n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 66s - loss: -30158654423.0400    \n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 66s - loss: -30473911357.4400    \n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 66s - loss: -30776680980.4800    \n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 66s - loss: -31080060928.0000    \n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 66s - loss: -31359021506.5600    \n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 65s - loss: -31675981905.9200    \n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 66s - loss: -31936002908.1600    \n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 66s - loss: -32225862533.1200    \n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 66s - loss: -32611025141.7600    \n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 66s - loss: -32901180129.2800    \n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 66s - loss: -33168849551.3600    \n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 65s - loss: -33479424716.8000    \n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 65s - loss: -33862360432.6400    \n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 66s - loss: -34114413240.3200    \n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 66s - loss: -34468731064.3200    \n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 66s - loss: -34745257738.2400    \n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 65s - loss: -35086807040.0000    \n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 66s - loss: -35231361966.0800    \n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 66s - loss: -35630745927.6800    \n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 66s - loss: -35994849976.3200    \n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 66s - loss: -36401062584.3200    \n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 66s - loss: -36717599825.9200    \n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 66s - loss: -37058447073.2800    \n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 66s - loss: -37412717117.4400    \n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 66s - loss: -37735140720.6400    \n",
      "0.433\n",
      "0.441\n",
      "0.457\n",
      "Epoch 1/50\n",
      "100/100 [==============================] - 66s - loss: -38117170462.7200    \n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 65s - loss: -38421814231.0400    \n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 66s - loss: -38740843397.1200    \n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 65s - loss: -39055813140.4800    \n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 65s - loss: -39377189150.7200    \n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 66s - loss: -39751110819.8400    \n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 66s - loss: -40086045941.7600    \n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 66s - loss: -40423504855.0400    \n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 66s - loss: -40790673162.2400    \n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 66s - loss: -41134397685.7600    \n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 66s - loss: -41502413455.3600    \n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 66s - loss: -41841680998.4000    \n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 66s - loss: -42201711493.1200    \n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 66s - loss: -42532961976.3200    \n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 66s - loss: -42852424212.4800    \n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 66s - loss: -43263522447.3600    \n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 66s - loss: -43576142561.2800    \n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 66s - loss: -43928511938.5600    \n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 66s - loss: -44291931176.9600    \n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 66s - loss: -44530184069.1200    \n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 66s - loss: -44861974568.9600    \n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 66s - loss: -45345437777.9200    \n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 66s - loss: -45692209807.3600    \n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 66s - loss: -46049019576.3200    \n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 66s - loss: -46528672563.2000    \n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 66s - loss: -46820825784.3200    \n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 66s - loss: -47186775408.6400    \n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 66s - loss: -47606976798.7200    \n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 66s - loss: -47931276533.7600    \n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 66s - loss: -48277396520.9600    \n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 66s - loss: -48486232023.0400    \n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 66s - loss: -49047252787.2000    \n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 66s - loss: -49345858109.4400    \n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 66s - loss: -49768322703.3600    \n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 66s - loss: -50170961715.2000    \n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 66s - loss: -50491919687.6800    \n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 66s - loss: -50857739550.7200    \n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 66s - loss: -51283642777.6000    \n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 66s - loss: -51718455582.7200    \n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 66s - loss: -52038840688.6400    \n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 66s - loss: -52438088048.6400    \n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 66s - loss: -52854941491.2000    \n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 66s - loss: -53120422584.3200    \n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 66s - loss: -53323498700.8000    \n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 66s - loss: -53879144243.2000    \n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 66s - loss: -54364798361.6000    \n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 66s - loss: -54826654679.0400    \n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 66s - loss: -55231591792.6400    \n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 66s - loss: -55583426396.1600    \n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 66s - loss: -55986945515.5200    \n",
      "0.491\n",
      "0.5\n",
      "0.47\n"
     ]
    }
   ],
   "source": [
    "score_arr = []\n",
    "\n",
    "for i in range(4):\n",
    "    epochs = 50\n",
    "    trinet.fit_generator(output_batch_generator(train_files, labels), \n",
    "                     steps_per_epoch=100, \n",
    "                     epochs=epochs,\n",
    "                        callbacks=[history])\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_identities = []\n",
    "    for idt in train_files.keys():\n",
    "        for f in train_files[idt]:\n",
    "            img = misc.imread(f)\n",
    "            predict = trinet.predict(img.reshape(1, 128, 64, 3))\n",
    "            all_embeddings.append(predict)\n",
    "            all_identities.append(idt)\n",
    "\n",
    "    i = 0\n",
    "    score_arr.append([])\n",
    "    for x in range(3):\n",
    "        score = evaluate_rank(trinet, 20, all_embeddings, all_identities, test_iter=1000)\n",
    "        print score\n",
    "        score_arr[i].append(score)\n",
    "    i += 1\n",
    "    \n",
    "    model_file = 'test_triplet_%dk_margin_1.0.h5' % ((2 + i) * 5)\n",
    "    trinet.save('/home/albert/github/tensorflow/%s' % model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = 'test_triplet_5k_margin_1.0.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trinet.save('/home/albert/github/tensorflow/%s' % model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model = load_model('/home/albert/github/tensorflow/%s' % model_file, \n",
    "                        custom_objects={'triplet_loss':triplet_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319.644582033\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "all_embeddings = []\n",
    "all_identities = []\n",
    "i = 0\n",
    "start = time.time()\n",
    "for idt in train_files.keys():\n",
    "    for f in train_files[idt]:\n",
    "        img = cv2.resize(misc.imread(f), (224,224))\n",
    "        predict = trinet.predict(img.reshape(1, 224, 224, 3))\n",
    "        all_embeddings.append(predict)\n",
    "        all_identities.append(idt)\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674\n",
      "0.649\n",
      "0.657\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "score_arr.append([])\n",
    "for x in range(3):\n",
    "    score = evaluate_rank(trinet, 20, all_embeddings, all_identities, test_iter=1000)\n",
    "    print score\n",
    "    score_arr[i].append(score)\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94eb5a2290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trinet.save('/home/albert/github/tensorflow/densenet_triplet_%d.h5' % 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/getting-started/faq/: use load_model to reinstantiate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all, lr_decay=1e-6, use log1p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
