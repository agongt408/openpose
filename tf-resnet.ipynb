{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import misc\n",
    "import pprint as pp\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mine Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAFFE_ROOT = '/home/albert/caffe/'\n",
    "img_dir = os.listdir(CAFFE_ROOT + 'data/market-1501/bounding_box_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = {}\n",
    "labels = []\n",
    "\n",
    "for f in img_dir:\n",
    "    if f[-4:] == '.jpg':\n",
    "        idt = int(f[0:f.index('_')])\n",
    "        if not any(idt == l for l in labels):\n",
    "            labels.append(idt)\n",
    "            train_files[idt] = []\n",
    "        path = CAFFE_ROOT + 'data/market-1501/bounding_box_train/' + f\n",
    "        train_files[idt].append(path)\n",
    "\n",
    "labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(train_files, labels, P=32, K=4):\n",
    "    while True:\n",
    "        batch = []\n",
    "        idt_choice = np.random.choice(labels, P, replace=False)\n",
    "        for p in range(len(idt_choice)):\n",
    "#             batch.append([])\n",
    "            k_choice = np.random.choice(range(len(train_files[idt_choice[p]])), K, replace=False)\n",
    "            for k in k_choice:\n",
    "                path = train_files[idt_choice[p]][k]\n",
    "                img = cv2.resize(misc.imread(path), (224, 224))\n",
    "                batch.append(img.tolist())\n",
    "        yield(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator = batch_generator(train_files, labels)\n",
    "# batch = generator.next()\n",
    "# batch = np.array(batch, dtype=np.uint8)\n",
    "\n",
    "# plt.figure(figsize=(8,10))\n",
    "# t = 0\n",
    "# for idt in range(20):\n",
    "#     t += 1\n",
    "#     plt.subplot(5, 4, t)\n",
    "#     plt.imshow(batch[idt])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_batch_generator(train_files, labels, P=18, K=4):\n",
    "    while True:\n",
    "        batch = []\n",
    "        idt_choice = np.random.choice(labels, P, replace=False)\n",
    "        for p in range(len(idt_choice)):\n",
    "            # n_choose = np.minimum(K, len(train_files[idt_choice[p]]))\n",
    "            k_choice = np.random.choice(range(len(train_files[idt_choice[p]])), K, replace=True)\n",
    "            for k in k_choice:\n",
    "                path = train_files[idt_choice[p]][k]\n",
    "                img = cv2.resize(misc.imread(path), (224, 224))\n",
    "                batch.append(img.tolist())\n",
    "        output = model.predict_on_batch(batch)\n",
    "        yield(output, np.zeros((output.shape[0], output.shape[1], output.shape[2], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_generator = output_batch_generator(train_files, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_batch = output_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 1, 1, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(output_batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "trinet = Sequential()\n",
    "trinet.add(Dense(1024, input_shape=(1, 1, 2048)))\n",
    "trinet.add(BatchNormalization())\n",
    "trinet.add(Activation('relu'))\n",
    "trinet.add(Dense(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log1p(x):\n",
    "    return Keras.log(1 + Keras.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(x1, x2):\n",
    "    return Keras.sum(Keras.abs(x1 - x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, margin=0.1, P=18, K=4, output_dim = 128):\n",
    "    embeddings = Keras.reshape(y_pred, (-1, output_dim))\n",
    "\n",
    "    loss = tf.Variable(1, dtype=tf.float32)\n",
    "\n",
    "    for i in range(P):\n",
    "        for a in range(K):\n",
    "            pred_anchor = embeddings[i*K + a]\n",
    "            hard_pos = Keras.max(dist(pred_anchor, embeddings[i*K:(i + 1)*K]))\n",
    "            hard_neg = Keras.min(dist(pred_anchor, Keras.concatenate([embeddings[0:i*K],\n",
    "                                                                      embeddings[(i + 1)*K:]], 0)))\n",
    "            loss += margin + hard_pos - hard_neg\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "trinet.compile(loss=triplet_loss, optimizer=Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 1, 1, 1024)        2098176   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1, 1, 128)         131200    \n",
      "=================================================================\n",
      "Total params: 2,233,472\n",
      "Trainable params: 2,231,424\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trinet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 107s - loss: -1521009.5750    \n",
      "Epoch 2/10\n",
      "2/5 [===========>..................] - ETA: 59s - loss: -1824288.7500"
     ]
    }
   ],
   "source": [
    "trinet.fit_generator(output_batch_generator(train_files, labels), steps_per_epoch=5, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.minimum(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 0, 1, 4, 1, 4, 0, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(5), 10, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "loss = tf.Variable(1, dtype=tf.float32)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
